{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import LSTM, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIX = pd.read_excel ('data_VIX.xlsx')\n",
    "AGG = pd.read_excel ('data_AGG.xlsx')\n",
    "DBC = pd.read_excel ('data_DBC.xlsx')\n",
    "VTI = pd.read_excel ('data_VTI.xlsx')\n",
    "all_data = pd.concat([VIX['Close'],AGG['Close'],DBC['Close'],VTI['Close']],axis=1)\n",
    "all_data.columns = ['VIX','AGG','DBC','VTI']\n",
    "all_data = all_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(all_data)\n",
    "all_data_scaled = pd.DataFrame(scaler.transform(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = None\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __build_model(self, input_shape, outputs):\n",
    "        model = Sequential([\n",
    "            LSTM(64, input_shape=input_shape, activation='relu'),\n",
    "            Flatten(),\n",
    "            Dense(outputs, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        def sharpe_loss(_, y_pred):\n",
    "            coeffs = tf.tile(y_pred, (self.data.shape[0], 1))\n",
    "            \n",
    "            portfolio_values = tf.reduce_sum(tf.multiply(coeffs, self.data), axis=1)\n",
    "            \n",
    "            portfolio_returns = (portfolio_values[1:] - portfolio_values[:-1]) / portfolio_values[:-1]  # % change formula\n",
    "\n",
    "            sharpe = K.mean(portfolio_returns) / K.std(portfolio_returns)\n",
    "            \n",
    "            return K.exp(-sharpe)\n",
    "        \n",
    "        model.compile(loss=sharpe_loss, optimizer='adam')\n",
    "        return model\n",
    "    \n",
    "    def get_allocations(self, data):\n",
    "        \n",
    "        data_w_ret = np.concatenate([ data.values[1:], data.pct_change().values[1:] ], axis=1)\n",
    "        \n",
    "        data = data.iloc[1:]\n",
    "        self.data = tf.cast(tf.constant(data), float)\n",
    "        \n",
    "        if self.model is None:\n",
    "            self.model = self.__build_model(data_w_ret.shape, len(data.columns))\n",
    "        \n",
    "        fit_predict_data = data_w_ret[np.newaxis,:]        \n",
    "        self.model.fit(fit_predict_data, np.zeros((1, len(data.columns))), epochs=20, shuffle=False)\n",
    "        return self.model.predict(fit_predict_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0298\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0250\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0202\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0155\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0108\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0061\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0014\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9966\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9915\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9862\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9805\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9746\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9684\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9619\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9544\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9457\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9353\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9228\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9073\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8877\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027362D0A4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "X = data[1500:1550]\n",
    "coeffs = model.get_allocations(pd.DataFrame(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1348214 , 0.24569641, 0.40750936, 0.21197282], dtype=float32)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
